from dotenv import load_dotenv
load_dotenv()
import os, sys
# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'crewAI', 'lib', 'crewai', 'src'))
import urllib3
urllib3.disable_warnings()
import argparse
import logging
import time
import json
from hashlib import md5
from typing import List, Dict, Any
from lib.config import is_debug, set_debug, is_verbose, set_verbose
from lib.executor import run_batch_for_items

# import litellm
# # litellm.json_logs = False
# litellm.log_level = "DEBUG"
# litellm._turn_on_debug()


from lib.logger import get_logger
from lib.utils import load_processed_set, save_processed_set, load_failure_counts, save_failure_counts, is_in_last_hour_of_competition, parse_targets_from_file

# å¼•å…¥ CTF å¹³å° API æ¥å£
try:
    from ctf_api import fetch_ctf_challenges, submit_ctf_flag, get_ctf_hint
except Exception:
    get_logger("main").error("CTF APIæ¨¡å—åŠ è½½å¤±è´¥ï¼Œå°†ç¦ç”¨CTF APIç›¸å…³åŠŸèƒ½")
    # å…è®¸åœ¨æ— è¯¥æ¨¡å—æ—¶ç»§ç»­è¿è¡Œï¼ˆä»…ç¦ç”¨ API åŠŸèƒ½ï¼‰
    fetch_ctf_challenges = None
    submit_ctf_flag = None
    get_ctf_hint = None

# mcps = MCPServerStdio(
#             command="python",
#             args=["mcp_server.py"],
#             cache_tools_list=True,
#         )


def _filter_items(batch_items, failure_counts, last_hour, watch_mode, logger):
    """
    è¿‡æ»¤å¤±è´¥æ¬¡æ•°è¶…è¿‡é˜ˆå€¼çš„é¢˜ç›®ï¼Œæ”¯æŒè½®è¯¢å’Œæ‰¹é‡æ¨¡å¼ã€‚
    """
    new_items = []
    for it in batch_items:
        code = str(it.get("code")) if it.get("code") is not None else None
        url = str(it.get("url"))
        c = failure_counts["by_code"].get(code, 0) if code else 0
        u = failure_counts["by_url"].get(url, 0)
        metric = c if watch_mode else max(c, u)
        threshold = 100
        if metric >= threshold:
            logger.info(f"è·³è¿‡é¢˜ç›®ï¼ˆå·²å¤±è´¥{metric}æ¬¡ï¼‰: {url}")
            continue
        if watch_mode:
            it["failure_counts"] = c
        new_items.append(it)
    return new_items

def _update_failure_counts(items, results, failure_counts):
    """
    æ ¹æ®ç»“æœæ›´æ–°å¤±è´¥è®¡æ•°ï¼ŒæˆåŠŸåˆ™æ¸…é›¶ï¼Œå¤±è´¥åˆ™+1ã€‚
    """
    for idx, it in enumerate(items):
        (_, flag_found, _) = results[idx]
        code = str(it.get("code")) if it.get("code") is not None else None
        url = str(it.get("url"))
        if flag_found:
            if code and code in failure_counts["by_code"]:
                del failure_counts["by_code"][code]
            if url in failure_counts["by_url"]:
                del failure_counts["by_url"][url]
        else:
            if code:
                failure_counts["by_code"][code] = failure_counts["by_code"].get(code, 0) + 1
            failure_counts["by_url"][url] = failure_counts["by_url"].get(url, 0) + 1

def _mark_processed(items, results, processed, mark_on_solve):
    """
    æ ‡è®°å·²å¤„ç†é¢˜ç›®ã€‚
    """
    for idx, it in enumerate(items):
        (_, flag_found, _) = results[idx]
        code = str(it.get("code")) if it.get("code") is not None else None
        url = str(it.get("url"))
        mark = (flag_found if mark_on_solve else True)
        if mark:
            if code:
                processed["processed_codes"].append(code)
            processed["processed_urls"].append(url)

def get_hexstrike_mcps_from_env() -> List[str]:
    """è¯»å– HEXSTRIKE MCP æœåŠ¡å™¨ URL å¹¶è¿”å› mcps åˆ—è¡¨ã€‚
    - ä½¿ç”¨å­—ç¬¦ä¸²å¼•ç”¨å½¢å¼ï¼ŒCrewAI å°†è‡ªåŠ¨è¿æ¥è¯¥ MCP æœåŠ¡å™¨ã€‚
    - å¦‚æœæœªè®¾ç½®ç¯å¢ƒå˜é‡åˆ™è¿”å›ç©ºåˆ—è¡¨ï¼Œè¡¨ç¤ºä¸å¯ç”¨ MCPã€‚
    """
    url = os.getenv("HEXSTRIKE_SERVER_URL", "").strip()
    if not url:
        return []
    # return [MCPServerHTTP(
    #     url=url,
    #     transport="streamable-http"
    # )]


def load_ctf_challenges_from_api(logger: logging.Logger) -> List[Dict[str, Any]]:
    """é€šè¿‡ CTF å¹³å° API è·å–é¢˜ç›®å¹¶æå– (url, code) åˆ—è¡¨ã€‚
    æ”¯æŒä¸åŒå­—æ®µåçš„å…¼å®¹ï¼š
    - URL å­—æ®µï¼šurl/target_url/target/challenge_urlï¼›
    - é¢˜ç›®ä»£ç å­—æ®µï¼šcode/challenge_code/id/challenge_idï¼›
    - å…¼å®¹ target_info: { ip: str, port: List[int] }ï¼Œå½“æœªæä¾›æ˜¾å¼ URL æ—¶ï¼Œä»æ­¤ç»“æ„ç”Ÿæˆ URLã€‚

    ç”Ÿæˆ URL è§„åˆ™ï¼š
    - ç«¯å£ä¸º 80 -> ä½¿ç”¨ http://ip
    - ç«¯å£ä¸º 443 -> ä½¿ç”¨ https://ip
    - å…¶ä»–ç«¯å£ -> ä½¿ç”¨ http://ip:port

    è‹¥æ¥å£ä¸å¯ç”¨æˆ–è§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚
    """
    if fetch_ctf_challenges is None:
        logger.warning("CTF APIæ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡ä»å¹³å°è·å–é¢˜ç›®ã€‚")
        return []
    try:
        raw = fetch_ctf_challenges()
        data = json.loads(raw or "{}")
        stage = data.get("current_stage")
        if stage == "debug" and not is_debug():
            logger.info("å½“å‰CTFå¹³å°ä¸ºè°ƒè¯•æ¨¡å¼!")
            return []
        chals = data.get("challenges", []) or []
        total = len(chals)
        solved_count = 0
        diff_counts = {"easy": 0, "medium": 0, "hard": 0}
        normalized: List[Dict[str, Any]] = []
        for c in chals:
            # ç»Ÿè®¡ä¿¡æ¯
            difficulty = str(c.get("difficulty", "")).lower()
            if difficulty in diff_counts:
                diff_counts[difficulty] += 1
            if bool(c.get("solved", False)):
                solved_count += 1

            url = (
                c.get("url")
                or c.get("target_url")
                or c.get("target")
                or c.get("challenge_url")
            )
            code = (
                c.get("code")
                or c.get("challenge_code")
                or c.get("id")
                or c.get("challenge_id")
            )
            # ä»…è¿”å›æœªè§£é¢˜ç›®
            if bool(c.get("solved", False)) and not is_debug():
                # pass
                continue

            if url:
                normalized.append({
                    "url": str(url),
                    "code": code,
                    "difficulty": difficulty,
                    "hint_viewed": bool(c.get("hint_viewed", False)),
                })
                continue

            # æ— æ˜¾å¼ URL æ—¶ï¼Œå°è¯•ä» target_info ç”Ÿæˆ
            target_info = c.get("target_info")
            if isinstance(target_info, dict):
                ip = target_info.get("ip")
                ports = target_info.get("port")
                # è§„èŒƒåŒ–ç«¯å£ä¸ºåˆ—è¡¨
                if isinstance(ports, int):
                    ports_list: List[int] = [ports]
                elif isinstance(ports, (list, tuple)):
                    # ä»…ä¿ç•™æ•´æ•°ç«¯å£
                    ports_list = [int(p) for p in ports if isinstance(p, (int, str)) and str(p).isdigit()]
                else:
                    ports_list = []

                candidate_urls: List[str] = []
                if ip:
                    if not ports_list:
                        # æœªç»™ç«¯å£ï¼Œé»˜è®¤ http 80
                        candidate_urls.append(f"http://{ip}")
                    else:
                        for p in ports_list:
                            candidate_urls.append(f"http://{ip}:{p}")
                                

                # å»é‡å¹¶å†™å…¥
                seen = set()
                for u in candidate_urls:
                    if u not in seen:
                        normalized.append({"url": u, "code": code, "difficulty": difficulty})
                        seen.add(u)

        # æŒ‰éš¾åº¦å¯¹æœªè§£é¢˜ç›®æ’åºï¼šeasy -> medium -> hard -> å…¶ä»–
        rank = {"easy": 0, "medium": 1, "hard": 2}
        normalized.sort(key=lambda it: (rank.get(str(it.get("difficulty", "")).lower(), 99), str(it.get("code") or ""), str(it.get("url") or "")))

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        if stage:
            logger.info(f"CTFå¹³å°é˜¶æ®µ: {stage}")
        logger.info(
            f"é¢˜ç›®æ€»æ•°: {total} | å·²è§£: {solved_count} | æœªè§£: {total - solved_count} | éš¾åº¦åˆ†å¸ƒ: easy={diff_counts['easy']}, medium={diff_counts['medium']}, hard={diff_counts['hard']}"
        )
        logger.info(f"è¿”å›æœªè§£é¢˜ç›®æ•°(è§„èŒƒåŒ–å): {len(normalized)}")
        return normalized
    except Exception as e:
        logger.error(f"è§£æCTFå¹³å°é¢˜ç›®å¤±è´¥: {e}")
        return []



def main():
    # è®¾ç½®å…¨å±€å¼‚å¸¸å¤„ç†
    def global_exception_handler(exc_type, exc_value, exc_traceback):
        if issubclass(exc_type, KeyboardInterrupt):
            print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
            return
        logger = get_logger("main")
        logger.critical("æœªå¤„ç†çš„å¼‚å¸¸:", exc_info=(exc_type, exc_value, exc_traceback))

    sys.excepthook = global_exception_handler

    parser = argparse.ArgumentParser(description="CTF æ‰§è¡Œå™¨ï¼ˆCrewAI ç‰ˆæœ¬ï¼‰")
    parser.add_argument("--url", help="å•ä¸ªç›®æ ‡URL", default="")
    parser.add_argument("--targets", help="æ‰¹é‡ç›®æ ‡æ–‡ä»¶è·¯å¾„", default="targets.txt")
    parser.add_argument("--use_ctf_api", help="ä»CTFå¹³å°è·å–é¢˜ç›®å¹¶æ‰¹é‡æ‰§è¡Œ", action="store_true")
    parser.add_argument("--auto_submit", help="å‘ç°flagåè‡ªåŠ¨æäº¤åˆ°CTFå¹³å°", action="store_true")
    parser.add_argument("--challenge_code", help="å•ç›®æ ‡æ¨¡å¼ä¸‹çš„é¢˜ç›®ä»£ç ï¼ˆç”¨äºè‡ªåŠ¨æäº¤ï¼‰", default="")
    parser.add_argument("--watch_ctf_api", help="å¾ªç¯ä»CTFå¹³å°æ£€æµ‹æ–°é¢˜å¹¶ä»…æ‰§è¡Œæœªåšé¢˜ç›®", action="store_true")
    parser.add_argument("--poll_interval", help="CTFå¹³å°è½®è¯¢é—´éš”ç§’æ•°", type=int, default=30)
    parser.add_argument("--hint_last_hour",  default=True, help="ä»…åœ¨æ¯ä¸ªæ¯”èµ›æ—¶æ®µçš„æœ€å1å°æ—¶ä¸ºæœªè§£é¢˜ç›®è·å–æç¤º", action="store_true")
    parser.add_argument("--debug",  default=False, help="è°ƒè¯•æ¨¡å¼æµç¨‹", action="store_true")
    parser.add_argument("--verbose",  default=False, help="verboseæ¨¡å¼ï¼Œè¾“å‡ºæ›´å¤šä¿¡æ¯", action="store_true")
    parser.add_argument("--max_concurrent",  default=1, help="æœ€å¤§å¹¶å‘æ‰§è¡Œæ•°", type=int)

    args = parser.parse_args()

    if args.debug:
        set_debug(True)
    if args.verbose:
        set_verbose(True)

    # # åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨ MCP æœåŠ¡å™¨
    # def run_server():
    #     from mcp_server import run_mcp_server
    #     run_mcp_server()

    # print("[1/2] æ­£åœ¨å¯åŠ¨ MCP æœåŠ¡å™¨...")
    # server_thread = threading.Thread(target=run_server, daemon=True)
    # server_thread.start()

    # # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
    # time.sleep(3)
    # print("[2/2] MCP æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œå¼€å§‹ CTF è§£é¢˜...")
    # print()

    # æ‰¹é‡æ¥æºï¼šä¼˜å…ˆä» CTF å¹³å°è·å–ï¼›å¦åˆ™ä»æ–‡ä»¶è¯»å–
    base_logger = get_logger("main")

    if args.use_ctf_api and args.watch_ctf_api:
        if fetch_ctf_challenges is None:
            print("CTFå¹³å°æ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•å¯ç”¨è½®è¯¢æ¨¡å¼")
            return 1
        base_logger.info(f"è¿›å…¥CTFå¹³å°è½®è¯¢æ¨¡å¼ï¼Œé—´éš” {args.poll_interval}sï¼Œæ ‡è®°è§„åˆ™: å°è¯•")
        processed = load_processed_set()
        failure_counts = load_failure_counts()
        while True:
            batch_items = load_ctf_challenges_from_api(base_logger)
            if not batch_items:
                base_logger.info("CTFå¹³å°æš‚æ— é¢˜ç›®æˆ–è§£æå¤±è´¥ï¼Œç­‰å¾…åé‡è¯•...")
                time.sleep(args.poll_interval)
                continue
           
            new_items = _filter_items(batch_items, failure_counts, is_in_last_hour_of_competition(), True, base_logger)

            if not new_items:
                base_logger.info("å¯æ‰§è¡Œé¢˜ç›®ä¸ºç©ºï¼ˆå‡å·²å¤±è´¥â‰¥3æ¬¡ï¼‰ï¼Œç­‰å¾…åé‡è¯•...")
                time.sleep(args.poll_interval)
                continue

            base_logger.info(f"å‘ç°æ–°é¢˜ç›®: {len(new_items)}ï¼Œå¼€å§‹æ‰§è¡Œ...")
            results = run_batch_for_items(new_items, args)
            _update_failure_counts(new_items, results, failure_counts)
            _mark_processed(new_items, results, processed, False)
            save_failure_counts(failure_counts)
            save_processed_set(processed)
            base_logger.info("è½®è¯¢å‘¨æœŸç»“æŸï¼Œç­‰å¾…åç»§ç»­...")
            time.sleep(args.poll_interval)
        # ä¸ä¼šåˆ°è¾¾æ­¤å¤„
    else:
        # å•æ¬¡æ‰¹é‡ï¼šä»å¹³å°æˆ–æ–‡ä»¶åŠ è½½ä¸€æ¬¡å¹¶æ‰§è¡Œ
        batch_items: List[Dict[str, Any]] = []
        if args.use_ctf_api:
            batch_items = load_ctf_challenges_from_api(base_logger)
            if not batch_items:
                print("CTFå¹³å°æœªè¿”å›é¢˜ç›®æˆ–è§£æå¤±è´¥ï¼Œé€€å‡º")
                return 1
        elif args.url:
            batch_items = [{"url": args.url, "code": md5(args.url.encode()).hexdigest()}]
        else:
            targets = parse_targets_from_file(args.targets)
            if not targets:
                print("æœªæä¾› --url ä¸”æœªåœ¨æ–‡ä»¶ä¸­æ‰¾åˆ°æœ‰æ•ˆç›®æ ‡ï¼Œé€€å‡º")
                return 1
            batch_items = [{"url": t, "code": md5(t.encode()).hexdigest()} for t in targets]

    # å¤±è´¥3æ¬¡é¢˜ç›®è·³è¿‡è¿‡æ»¤ï¼ˆå•æ¬¡æ‰¹é‡æ¨¡å¼ï¼‰
    failure_counts = load_failure_counts()
    filtered_items = _filter_items(batch_items, failure_counts, is_in_last_hour_of_competition(), False, base_logger)

    if not filtered_items:
        print("å¯æ‰§è¡Œé¢˜ç›®ä¸ºç©ºï¼ˆå‡å·²å¤±è´¥â‰¥10æ¬¡ï¼‰ï¼Œé€€å‡º")
        return 1

    results_summary = run_batch_for_items(filtered_items, args)
    _update_failure_counts(filtered_items, results_summary, failure_counts)
    save_failure_counts(failure_counts)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())