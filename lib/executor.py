import os, time, json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Tuple
from pebble import ProcessPool, ProcessExpired
from concurrent.futures import TimeoutError
import multiprocessing
import traceback
from lib.logger import get_logger
from lib.utils import format_duration, is_in_last_hour_of_competition, get_embedder_config_from_env, get_db_storage_path
from lib.config import is_debug, is_verbose

try:
    from ctf_api import fetch_ctf_challenges, submit_ctf_flag, get_ctf_hint
except Exception:
    # å…è®¸åœ¨æ— è¯¥æ¨¡å—æ—¶ç»§ç»­è¿è¡Œï¼ˆä»…ç¦ç”¨ API åŠŸèƒ½ï¼‰
    fetch_ctf_challenges = None
    submit_ctf_flag = None
    get_ctf_hint = None

# çº¿ç¨‹å®‰å…¨çš„memory_key_status
manager = multiprocessing.Manager()
memory_key_status: Dict[str, bool] = manager.dict() 
memory_lock = manager.Lock()

class CTFExecutor:
    def __init__(self, cdp_url: str = None):
        from lib.workflow import CTFOpportunisticWorkflow
        from lib.llm import CrewLLMConfig
        from lib.tools import setup_tools
        from lib.knowledge import get_knowledge
        # init_rag_countext()
        knowledge = get_knowledge()
        # åˆå§‹åŒ–ç³»ç»Ÿ
        self.system = CTFOpportunisticWorkflow(llm_config=CrewLLMConfig(), tools=setup_tools(cdp_url), knowledge=knowledge)
        self.logger = get_logger("executor")


    def parse_result(self, result: str, target_code: str, target_url: str, file_name: str, target_key: str) -> str:
        # è¿è¡Œå®Œæˆåï¼Œå°½é‡åªä¿ç•™ flag å†…å®¹ä½œä¸ºè¿”å›
        from lib.tools import FlagValidatorTool
        fv = FlagValidatorTool()
        validation = fv._run(str(result))
        flag_found = validation.startswith("âœ… å‘ç°æœ‰æ•ˆFlag")
        flag_content = validation.split(":", 1)[1].strip() if flag_found else ""
        self.logger.info(f"CTFæŒ‘æˆ˜å®Œæˆï¼Œ{target_code} - {target_url} {('å‘ç°Flag: ' + flag_content) if flag_found else 'æœªæ‰¾åˆ°flag'}")
        # è¿”å›å°½å¯èƒ½ç®€åŒ–çš„ç»“æœï¼šä»…è¿”å› flag å­—ç¬¦ä¸²ï¼ˆè‹¥æœªæ‰¾åˆ°åˆ™è¿”å›åŸå§‹ç»“æœä»¥ä¾¿æ’é”™ï¼‰
        return flag_content if flag_found else result

    def _crew_step_callback(self, step_output):
        """CrewAIæ­¥éª¤å›è°ƒï¼Œç”¨äºç›‘æ§æ‰§è¡Œè¿›åº¦"""
        self.ailogger.info(f"æ­¥éª¤è¾“å‡º: {str(step_output)}")

    def execute_ctf(self, target_code: str, target_url: str, hint: str | None = None, failure_counts: int = 0):
        self.logger.info(f"ğŸ¯ å¼€å§‹CTFæŒ‘æˆ˜: {target_code} - {target_url} - {hint} - {failure_counts}")
        embedder_conf = get_embedder_config_from_env()
        # ä¸ºæ¯é¢˜è®¾ç½®ç‹¬ç«‹çš„å‘½åç©ºé—´ï¼Œé¿å…è®°å¿†æ··æ·†
        target_key = f"ctf_{target_code}_{target_url.replace('://', '_').replace('/', '_')}"
        # os.environ["CREWAI_STORAGE_DIR"] = f"{target_key}"
        # å†…éƒ¨åˆå§‹åŒ–
        from crewai import Crew, Process
        from crewai.memory.short_term.short_term_memory import ShortTermMemory
        from crewai.memory.entity.entity_memory import EntityMemory
        from crewai.memory.long_term.long_term_memory import LongTermMemory

        self.ailogger = get_logger(f"ai.{target_key}", False)
        
        if is_debug():
            worker_agents = self.system.create_debug_agents()
            manager_agent = self.system.create_debug_manager_agent()
            workflow = self.system.create_debug_workflow(target_url, target_code, hint)
        else:
            # è·å–agentså’Œå·¥ä½œæµ
            agents = self.system._get_opportunistic_agents()
            worker_agents = [agent for key, agent in agents.items() if key != "opportunistic_coordinator"]
            manager_agent = agents["opportunistic_coordinator"]
            workflow = self.system.create_opportunistic_workflow(target_url, target_code, hint)

        db_storage_path = get_db_storage_path(target_key)

        Path(f"logs/{datetime.now().strftime('%Y-%m-%d')}/crew").mkdir(parents=True, exist_ok=True)
        file_name = f"{datetime.now().strftime('%Y-%m-%d')}/crew/{target_code}_{target_url.replace('://', '_').replace('/', '_')}.log"
        try:
            stream=False
            # åˆ›å»ºåˆ†å±‚crew
            crew = Crew(
                name=f"ctf_attack_{target_code}",
                output_log_file=f"logs/{file_name}",
                agents=worker_agents,
                tasks=workflow,
                stream=stream,
                process=Process.hierarchical,  # å…³é”®æ”¹è¿›ï¼šä½¿ç”¨åˆ†å±‚æµç¨‹
                manager_agent=manager_agent,  # åè°ƒå™¨ä½œä¸ºç»ç†
                llm=self.system.llm_config.get_llm_by_role("opportunistic_coordinator"),
                # chat_llm=self.system.llm_config.get_llm_by_role("opportunistic_coordinator"),
                # function_calling_llm=self.system.llm_config.get_llm_by_role("tool_call"),
                verbose=is_verbose(),
                tracing=is_verbose(),
                memory=True,
                max_rpm=30,  # æ›´åˆç†çš„é™åˆ¶
                max_iter=8,   # ç»™äºˆæ›´å¤šæ¨ç†ç©ºé—´
                max_execution_time=1700,  # 1800ç§’è¶…æ—¶
                task_callback=self._crew_step_callback,  # æ·»åŠ ä»»åŠ¡å›è°ƒ
                step_callback=self._crew_step_callback,  # æ·»åŠ æ­¥éª¤å›è°ƒ
                # embedder=embedder_conf,
                long_term_memory=LongTermMemory(
                    path=f"{db_storage_path}/long_term_memory_storage.db"
                )
            )

            crew._short_term_memory = ShortTermMemory(
                crew=crew,
                embedder_config=embedder_conf,
                path=db_storage_path,
            )
            crew.short_term_memory = crew._short_term_memory
            crew._entity_memory = EntityMemory(
                crew=crew, embedder_config=embedder_conf, path=db_storage_path
            )
            crew.entity_memory = crew._entity_memory

        except Exception as e:
            self.logger.error(f"åˆ›å»ºCrewå¤±è´¥: {e} {traceback.format_exc()}")
            return f"âš ï¸ åˆ›å»ºCrewå¤±è´¥: {e}"

        try:
            def _is_memory_initialized(target_key: str) -> bool:
                """çº¿ç¨‹å®‰å…¨åœ°æ£€æŸ¥memoryæ˜¯å¦å·²åˆå§‹åŒ–"""
                with memory_lock:
                    return memory_key_status.get(target_key, False)
            if not _is_memory_initialized(target_key):
                for command_type in ['short', 'long', 'entity']: # kickoff_outputsã€knowledge çœ‹æƒ…å†µ
                    try:
                        crew.reset_memories(command_type=command_type)
                    except:
                        pass
                with memory_lock:
                    memory_key_status[target_key] = True
            result = crew.kickoff()
            if stream:
                for chunk in result:
                    pass
                try:
                    crew.reset_memories(command_type='long')      # Long-term memory
                except:
                    pass
                try:
                    crew.reset_memories(command_type='entity')    # Entity memory
                except:
                    pass
                # try:
                #     crew.reset_memories(command_type='knowledge') # Knowledge storage
                # except:
                #     pass
                with memory_lock:
                    memory_key_status[target_key] = True
            result = crew.kickoff()
            if stream:
                for chunk in result:
                    pass
                    # print(chunk.content, end="", flush=True)
                result = result.result
            self.logger.info(f"usage_metrics: {crew.usage_metrics}")
            return self.parse_result(result, target_code, target_url, file_name, target_key)
        except Exception as e:
            self.logger.error(f"kickoff æ‰§è¡Œå¤±è´¥: {e} {traceback.format_exc()}")
            return f"âš ï¸ kickoff å¼‚å¸¸: {e}"


class PebbleCTFExecutor:
    """ç²¾ç®€çš„Pebble CTFæ‰§è¡Œå™¨ - ä¿®å¤åºåˆ—åŒ–é—®é¢˜"""
    
    def __init__(self, cdp_urls: List[str] = None, max_concurrent: int = 2):
        self.cdp_urls = cdp_urls or [os.getenv("STEEL_CONNECT_URL", "ws://127.0.0.1:13001")]
        self.max_workers = min(len(self.cdp_urls), max_concurrent)
        
        # ä½¿ç”¨ç®€å•çš„æ—¥å¿—è®¾ç½®ï¼Œé¿å…ä¼ é€’å¤æ‚å¯¹è±¡
        self.logger = get_logger("pebble")
        
        self.process_pool = ProcessPool(
            max_workers=self.max_workers,
            max_tasks=0,
            initializer=self._process_initializer
        )
        self.logger.info(f"Pebbleæ‰§è¡Œå™¨åˆå§‹åŒ–å®Œæˆ - è¿›ç¨‹æ•°: {self.max_workers}")

    def _process_initializer(self):
        """è¿›ç¨‹åˆå§‹åŒ–"""
        pass
        # åœ¨å­è¿›ç¨‹ä¸­é‡æ–°åˆå§‹åŒ–æ—¥å¿—
        # logging.basicConfig(
        #     level=logging.INFO,
        #     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        # )

    def run_batch_concurrently(self, batch_items: List[Dict[str, Any]], args) -> List[Tuple[str, bool, str]]:
        """å¹¶å‘æ‰§è¡Œæ‰¹é‡ä»»åŠ¡ - ä¿®å¤åºåˆ—åŒ–é—®é¢˜"""
        self.logger.info(f"å¼€å§‹æ‰§è¡Œ {len(batch_items)} ä¸ªCTFä»»åŠ¡")
        
        start_time = time.time()
        futures = {}
        results = []
        
        # æäº¤æ‰€æœ‰ä»»åŠ¡ - åªä¼ é€’å¯åºåˆ—åŒ–çš„æ•°æ®
        for i, item in enumerate(batch_items):
            cdp_url = self.cdp_urls[i % len(self.cdp_urls)]
            challenge_code = item.get("code", f"unknown_{i}")
            
            # å‡†å¤‡å¯åºåˆ—åŒ–çš„ä»»åŠ¡æ•°æ®
            task_data = {
                'url': item['url'],
                'code': challenge_code,
                'failure_counts': item.get('failure_counts', 0),
                'cdp_url': cdp_url,
                'hint_last_hour': getattr(args, 'hint_last_hour', False)
            }
            
            future = self.process_pool.schedule(
                execute_single_task,  # ä½¿ç”¨æ¨¡å—çº§å‡½æ•°ï¼Œé¿å…ä¼ é€’self
                args=(task_data,),    # åªä¼ é€’å¯åºåˆ—åŒ–æ•°æ®
                timeout=1700
            )
            time.sleep(1)
            futures[future] = (i, item)
            self.logger.info(f"æäº¤ä»»åŠ¡: {challenge_code} - {item['url']}")
        
        # ç›‘æ§ä»»åŠ¡æ‰§è¡Œ
        completed_count = 0
        total_tasks = len(futures)
        
        while futures and completed_count < total_tasks:
            finished_futures = []
            for future, task_info in list(futures.items()):
                if future.done():
                    finished_futures.append((future, task_info))
            
            for future, (i, item) in finished_futures:
                challenge_code = item.get("code", "unknown")
                
                try:
                    result = future.result()
                    results.append((i, result))
                    self.logger.info(f"ä»»åŠ¡å®Œæˆ: {challenge_code} - ç»“æœ: {'æˆåŠŸ' if result[1] else 'å¤±è´¥'}")
                    
                except (ProcessExpired, TimeoutError):
                    results.append((i, (item["url"], False, "æ‰§è¡Œè¶…æ—¶")))
                    self.logger.warning(f"ä»»åŠ¡è¶…æ—¶: {challenge_code}")
                    
                except Exception as e:
                    results.append((i, (item["url"], False, f"æ‰§è¡Œå¼‚å¸¸: {str(e)}")))
                    self.logger.error(f"ä»»åŠ¡å¼‚å¸¸: {challenge_code} - {e}")
                
                completed_count += 1
                del futures[future]
            
            # è¿›åº¦æ›´æ–°
            if futures:
                # progress = (completed_count / total_tasks) * 100
                # self.logger.info(f"è¿›åº¦: {completed_count}/{total_tasks} ({progress:.1f}%)")
                time.sleep(5)
        
        # æ•´ç†ç»“æœ
        final_results = self._organize_results(results, batch_items)
        
        # ç”Ÿæˆæ‘˜è¦
        self._generate_summary(final_results, time.time() - start_time)
        
        return final_results

    def _organize_results(self, results: List, batch_items: List) -> List[Tuple[str, bool, str]]:
        """æ•´ç†ç»“æœç¡®ä¿é¡ºåºæ­£ç¡®"""
        sorted_results = [None] * len(batch_items)
        for i, result in results:
            if i < len(batch_items):
                sorted_results[i] = result
        
        # å¡«å……ç¼ºå¤±ç»“æœ
        return [
            sorted_results[i] if sorted_results[i] is not None 
            else (batch_items[i]["url"], False, "ä»»åŠ¡æœªå®Œæˆ")
            for i in range(len(batch_items))
        ]

    def _generate_summary(self, results: List[Tuple[str, bool, str]], total_elapsed: float):
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        total = len(results)
        success_count = sum(1 for _, success, _ in results if success)
        
        self.logger.info("=" * 50)
        self.logger.info("æ‰§è¡Œæ‘˜è¦:")
        self.logger.info(f"  æ€»ä»»åŠ¡æ•°: {total}")
        self.logger.info(f"  æˆåŠŸæ•°é‡: {success_count}")
        self.logger.info(f"  æˆåŠŸç‡: {(success_count/total)*100:.1f}%")
        self.logger.info(f"  æ€»è€—æ—¶: {total_elapsed:.1f}ç§’")
        self.logger.info("=" * 50)
        
        # è¾“å‡ºæ‰¾åˆ°çš„Flag
        found_flags = [flag for _, success, flag in results if success and flag]
        if found_flags:
            print("\nå‘ç°çš„Flag:")
            for flag in found_flags:
                print(f"  {flag}")

    def close(self):
        """å®‰å…¨å…³é—­"""
        self.logger.info("å…³é—­è¿›ç¨‹æ± ...")
        try:
            self.process_pool.close()
            self.process_pool.join(timeout=0.1)
        except:
            self.process_pool.stop()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# æ¨¡å—çº§å‡½æ•° - è¿™äº›å¯ä»¥åœ¨å­è¿›ç¨‹ä¸­å®‰å…¨æ‰§è¡Œ
def execute_single_task(task_data: Dict[str, Any]) -> Tuple[str, bool, str]:
    """åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­æ‰§è¡Œå•ä¸ªä»»åŠ¡ - æ¨¡å—çº§å‡½æ•°é¿å…åºåˆ—åŒ–é—®é¢˜"""
    # åœ¨å­è¿›ç¨‹ä¸­è®¾ç½®æ—¥å¿—
    logger = setup_task_logger(task_data['code'])
    
    url = task_data['url']
    challenge_code = task_data['code']
    
    try:
        logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {challenge_code} - {url}")
        start_time = time.perf_counter()
        # è·å–æç¤ºä¿¡æ¯
        hint_text = get_hint_if_needed(challenge_code, task_data['hint_last_hour'], logger)
        # ä¸ºæ¯é¢˜è®¾ç½®ç‹¬ç«‹çš„å‘½åç©ºé—´ï¼Œé¿å…è®°å¿†æ··æ·†
        # target_key = f"ctf_{task_data['code']}_{task_data['url'].replace('://', '_').replace('/', '_')}"
        # os.environ["CREWAI_STORAGE_DIR"] = f"{target_key}"
        
        # æ‰§è¡ŒCTFé€»è¾‘ - åœ¨å­è¿›ç¨‹ä¸­åˆ›å»ºæ‰§è¡Œå™¨
        executor = CTFExecutor(cdp_url=task_data['cdp_url'])
        result = executor.execute_ctf(
            str(challenge_code), 
            url, 
            hint_text, 
            task_data.get('failure_counts', 0)
        )

        elapsed_ms = (time.perf_counter() - start_time) * 1000
        elapsed_str = format_duration(elapsed_ms)
        logger.info(f"ä»»åŠ¡å®Œæˆ: {challenge_code} - è€—æ—¶: {elapsed_str}")
        
        # éªŒè¯ç»“æœ
        flag_found, flag_content = validate_result(result, challenge_code, logger)
        
        if flag_found:
            auto_submit_flag(challenge_code, flag_content, logger)
            logger.info(f"ä»»åŠ¡æˆåŠŸ - æ‰¾åˆ°Flag: {flag_content}")
        else:
            logger.info("ä»»åŠ¡å®Œæˆä½†æœªæ‰¾åˆ°Flag")
        
        return (url, flag_found, flag_content)
        
    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e} {traceback.format_exc()}")
        return (url, False, f"æ‰§è¡Œå¼‚å¸¸: {str(e)}")

def setup_task_logger(challenge_code: str):
    """è®¾ç½®ä»»åŠ¡ä¸“ç”¨æ—¥å¿—å™¨ - æ¨¡å—çº§å‡½æ•°"""
    safe_code = "".join(c for c in str(challenge_code) if c.isalnum() or c in ('-', '_'))
    logger = get_logger(f"task.{safe_code}")
    return logger


def get_hint_if_needed(challenge_code: str, hint_last_hour: bool, logger) -> str:
    """è·å–æç¤ºä¿¡æ¯ - æ¨¡å—çº§å‡½æ•°"""
    if not (hint_last_hour and challenge_code):
        return None
        
    try:
        if is_in_last_hour_of_competition() or is_debug():
            raw_hint = get_ctf_hint(str(challenge_code)) if get_ctf_hint else ""
            hint_obj = json.loads(raw_hint or "{}") if isinstance(raw_hint, str) else raw_hint
            return hint_obj.get("hint_content")
    except Exception as e:
        logger.error(f"è·å–æç¤ºå¤±è´¥: {e}")
        
    return None


def validate_result(result: str, challenge_code: str, logger) -> Tuple[bool, str]:
    """éªŒè¯æ‰§è¡Œç»“æœ - æ¨¡å—çº§å‡½æ•°"""
    try:
        from lib.tools import FlagValidatorTool
        fv = FlagValidatorTool()
        validation = fv._run(str(result))
        
        flag_found = validation.startswith("âœ… å‘ç°æœ‰æ•ˆFlag")
        flag_content = validation.split(":", 1)[1].strip() if flag_found else ""
        
        return flag_found, flag_content
    except Exception as e:
        logger.error(f"éªŒè¯ç»“æœå¤±è´¥: {e}")
        return False, ""


def auto_submit_flag(challenge_code: str, flag_content: str, logger):
    """è‡ªåŠ¨æäº¤Flag - æ¨¡å—çº§å‡½æ•°"""
    try:
        if submit_ctf_flag:
            submit_res = submit_ctf_flag(str(challenge_code), flag_content)
            logger.info(f"Flagæäº¤æˆåŠŸ:{challenge_code} - {submit_res}")
    except Exception as e:
        logger.error(f"Flagæäº¤å¤±è´¥:{challenge_code} - {e}")


# å…¨å±€æ‰§è¡Œå™¨å®ä¾‹
_executor = None

def run_batch_for_items(batch_items: List[Dict[str, Any]], args) -> List[Tuple[str, bool, str]]:
    """ä¸»è¦æ‰§è¡Œå‡½æ•°"""
    global _executor
    
    cdp_urls = get_cdp_urls()
    
    logger = get_logger("main")
    
    if _executor is None:
        _executor = PebbleCTFExecutor(cdp_urls, max_concurrent=args.max_concurrent)
    
    try:
        return _executor.run_batch_concurrently(batch_items, args)
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        return [(item["url"], False, f"æ‰§è¡Œå¼‚å¸¸: {e}") for item in batch_items]


def get_cdp_urls() -> List[str]:
    """è·å–CDP URLs"""
    cdp_urls_str = os.getenv("CDP_URLS", "")
    if cdp_urls_str:
        return [url.strip() for url in cdp_urls_str.split(",") if url.strip()]
    return [os.getenv("STEEL_CONNECT_URL", "ws://127.0.0.1:13001")]


# æ¸…ç†å‡½æ•°
import atexit
def cleanup():
    if _executor:
        _executor.close()
atexit.register(cleanup)

import signal
def signal_handler(sig, frame):
    cleanup()
    exit(0)
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
